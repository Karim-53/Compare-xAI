{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "from skimage.segmentation import quickshift\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "from context_explainer import ContextExplainer\n",
    "from application_utils.image_utils import *\n",
    "from application_utils.utils_torch import ModelWrapperTorch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"results/resnet_random_context_only.pickle\"\n",
    "random_context_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet152(pretrained=True).to(device).eval();\n",
    "model_wrapper = ModelWrapperTorch(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../downloads/imagenet14/test\"\n",
    "test_data = sorted(\n",
    "    [base_path + \"/\" + f for f in os.listdir(base_path) if f.endswith(\".JPEG\")]\n",
    ")\n",
    "\n",
    "target_count = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "indexes = np.random.choice(len(test_data), target_count, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(save_path):\n",
    "    print(\"loaded\")\n",
    "    with open(save_path, 'rb') as handle:\n",
    "        all_res = pickle.load(handle)\n",
    "else:\n",
    "    all_res = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for counter, index in enumerate(tqdm(indexes)):\n",
    "\n",
    "    image_path = test_data[index]\n",
    "    \n",
    "    img_filename = image_path.split(\"/\")[-1]\n",
    "    \n",
    "    if counter < len(all_res):\n",
    "        # if an experiment is already done, skip it\n",
    "        print(\"skip\", counter)\n",
    "        assert(all_res[counter][\"img_filename\"] == img_filename)\n",
    "        continue\n",
    "\n",
    "    image, labels = get_image_and_labels(image_path, device)\n",
    "\n",
    "    predictions = model_wrapper(np.expand_dims(image,0))\n",
    "    class_idx = predictions[0].argsort()[::-1][0]\n",
    "    \n",
    "    baseline = np.zeros_like(image)\n",
    "    segments = quickshift(image, kernel_size=3, max_dist=300, ratio=0.2)\n",
    "\n",
    "    xf = ImageXformer(image, baseline, segments)\n",
    "\n",
    "    ctx = ContextExplainer(model_wrapper, data_xformer=xf, output_indices=class_idx, batch_size=20, verbose=False)\n",
    "\n",
    "    context1 = ctx.input\n",
    "    context2 = ctx.baseline\n",
    "\n",
    "    n_samples = 9\n",
    "\n",
    "    new_contexts = []\n",
    "    if random_context_only:\n",
    "        seen_contexts_tuples = []\n",
    "        n_samples += 2\n",
    "    else:\n",
    "        seen_contexts_tuples = [tuple(context1), tuple(context2)]\n",
    "\n",
    "    for n in range(n_samples):\n",
    "        while True:\n",
    "            context = np.random.randint(0, high=2, size=len(context1)).astype(bool)\n",
    "            context_tuple = tuple(context)\n",
    "            if context_tuple not in seen_contexts_tuples:\n",
    "                break\n",
    "        new_contexts.append(context)\n",
    "        seen_contexts_tuples.append(context_tuple)\n",
    "\n",
    "    if random_context_only:\n",
    "        all_contexts = new_contexts\n",
    "    else:\n",
    "        all_contexts =[context1, context2] + new_contexts\n",
    "\n",
    "    res = ctx.detect_with_running_contexts(all_contexts)\n",
    "    \n",
    "    all_res.append({\"img_filename\": img_filename, \"result\": res})\n",
    "    \n",
    "    with open(save_path, 'wb') as handle:\n",
    "        pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "with open(save_path, 'wb') as handle:\n",
    "    pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
