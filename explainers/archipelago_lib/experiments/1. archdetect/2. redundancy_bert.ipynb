{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "import scipy\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "from context_explainer import ContextExplainer\n",
    "from application_utils.text_utils import *\n",
    "from application_utils.text_utils_torch import BertWrapperTorch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"results/bert_random_context_only.pickle\"\n",
    "random_context_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst-2'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model_path = \"../../downloads/pretrained_bert\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "class_idx = 1\n",
    "model_wrapper = BertWrapperTorch(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sst_sentences(split=\"test\", path=\"../../downloads/sst_data/sst_trees.pickle\")\n",
    "baseline_token = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'rb') as handle:\n",
    "        all_res = pickle.load(handle)\n",
    "else:\n",
    "    all_res = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for s_idx, text in enumerate(tqdm(sentences)):\n",
    "    \n",
    "    if s_idx < len(all_res):\n",
    "        # if an experiment is already done, skip it\n",
    "        assert(all_res[s_idx][\"text\"] == text)\n",
    "        print(\"skip\", s_idx)\n",
    "        continue\n",
    "\n",
    "    text_ids, baseline_ids = get_input_baseline_ids(text, baseline_token, tokenizer)\n",
    "\n",
    "    xf = TextXformer(text_ids, baseline_ids) \n",
    "    ctx = ContextExplainer(model_wrapper, data_xformer=xf, output_indices=class_idx, batch_size=20, verbose=False)\n",
    "\n",
    "    context1 = ctx.input\n",
    "    context2 = ctx.baseline\n",
    "\n",
    "    n_samples = 9\n",
    "\n",
    "    new_contexts = []\n",
    "    if random_context_only:\n",
    "        seen_contexts_tuples = []\n",
    "        n_samples += 2\n",
    "    else:\n",
    "        seen_contexts_tuples = [tuple(context1), tuple(context2)]\n",
    "\n",
    "    for n in range(n_samples):\n",
    "        while True:\n",
    "            context = np.random.randint(0, high=2, size=len(context1)).astype(bool)\n",
    "            context_tuple = tuple(context)\n",
    "            if context_tuple not in seen_contexts_tuples:\n",
    "                break\n",
    "        new_contexts.append(context)\n",
    "        seen_contexts_tuples.append(context_tuple)\n",
    "\n",
    "    if random_context_only:\n",
    "        all_contexts = new_contexts\n",
    "    else:\n",
    "        all_contexts = [context1, context2] + new_contexts\n",
    "\n",
    "    res = ctx.detect_with_running_contexts(all_contexts)\n",
    "    \n",
    "    all_res.append({\"text\": text, \"result\": res})\n",
    "    \n",
    "    if (s_idx+1) % 3 == 0:      \n",
    "        with open(save_path, 'wb') as handle:\n",
    "            pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(save_path, 'wb') as handle:\n",
    "    pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
