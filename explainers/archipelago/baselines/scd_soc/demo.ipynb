{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "# from bert.run_classifier import BertTokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "sys.path.append(\"./hiexpl\")\n",
    "from helper import *\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')#, do_lower_case=True, cache_dir='bert/cache')\n",
    "bert_path = \"../../downloads/pretrained_bert\"\n",
    "model = get_bert(bert_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"though a bit of a patch ##work in script and production , a glossy , rich green , environment almost makes the picture work .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9403,  2.7804]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "preds = get_prediction(model, [sentence], tokenizer, device)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"soc\"\n",
    "# method = \"scd\"\n",
    "# method = \"cd\" # doesnt work at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocab from vocab/vocab_sst.pkl\n"
     ]
    }
   ],
   "source": [
    "lm_path = \"../../downloads/pretrained_hiexpl_lm/best_snapshot_devloss_11.708949835404105_iter_2000_model.pt\"\n",
    "algo = get_hiexpl(method, model, lm_path, tokenizer, device, sample_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens\n",
      " ['though', 'a', 'bit', 'of', 'a', 'patch', '#', '#', 'work', 'in', 'script', 'and', 'production', ',', 'a', 'glossy', ',', 'rich', 'green', ',', 'environment', 'almost', 'makes', 'the', 'picture', 'work', '.']\n",
      "\n",
      "scores\n",
      " {(1, 1): 0.146915465593338, (2, 2): 0.3505658805370331, (3, 3): 0.11184519529342651, (4, 4): 0.23161092400550842, (5, 5): 0.38228902220726013, (6, 6): 0.08281208574771881, (7, 7): 0.24915504455566406, (8, 8): 0.10236231982707977, (9, 9): 0.2930784225463867, (10, 10): 0.41771554946899414, (11, 11): 0.17606183886528015, (12, 12): 0.46679267287254333, (13, 13): -0.0669143944978714, (14, 14): -0.08309005200862885, (15, 15): 0.2622664272785187, (16, 16): -0.14915215969085693, (17, 17): 0.0672696977853775, (18, 18): 1.3571451902389526, (19, 19): 0.06354774534702301, (20, 20): 0.17312249541282654, (21, 21): 0.6043580770492554, (22, 22): 0.4030352234840393, (23, 23): 0.9028497934341431, (24, 24): -0.015416771173477173, (25, 25): 0.4994756579399109, (26, 26): 0.9656969904899597, (27, 27): 0.2780976891517639}\n"
     ]
    }
   ],
   "source": [
    "scores, tokens = explain_sentence(sentence, algo, tokenizer)\n",
    "print(\"tokens\\n\",tokens)\n",
    "print(\"\\nscores\\n\",scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
